{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebcbf418-ce0a-458e-be9d-0ce681f93fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e179f0a-d4b6-4cf8-995e-5b5ec6e74d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd123f3d-6da7-41af-844c-fa0743af9028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9f58073-267c-418b-b539-01f4bc6f0016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_jsonl_transfer(origin_path, new_path):\n",
    "    \"\"\"\n",
    "    Â∞ÜÂéüÂßãÊï∞ÊçÆÈõÜËΩ¨Êç¢‰∏∫Â§ßÊ®°ÂûãÂæÆË∞ÉÊâÄÈúÄÊï∞ÊçÆÊ†ºÂºèÁöÑÊñ∞Êï∞ÊçÆÈõÜ\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "\n",
    "    # ËØªÂèñÊóßÁöÑJSONLÊñá‰ª∂\n",
    "    with open(origin_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            # Ëß£ÊûêÊØè‰∏ÄË°åÁöÑjsonÊï∞ÊçÆ\n",
    "            data = json.loads(line)\n",
    "            input_text = data[\"text\"]\n",
    "            entities = data[\"entities\"]\n",
    "            match_names = [\"Âú∞ÁÇπ\", \"‰∫∫Âêç\", \"Âú∞ÁêÜÂÆû‰Ωì\", \"ÁªÑÁªá\"]\n",
    "            \n",
    "            entity_sentence = \"\"\n",
    "            for entity in entities:\n",
    "                entity_json = dict(entity)\n",
    "                entity_text = entity_json[\"entity_text\"]\n",
    "                entity_names = entity_json[\"entity_names\"]\n",
    "                for name in entity_names:\n",
    "                    if name in match_names:\n",
    "                        entity_label = name\n",
    "                        break\n",
    "                \n",
    "                entity_sentence += f\"\"\"{{\"entity_text\": \"{entity_text}\", \"entity_label\": \"{entity_label}\"}}\"\"\"\n",
    "            \n",
    "            if entity_sentence == \"\":\n",
    "                entity_sentence = \"Ê≤°ÊúâÊâæÂà∞‰ªª‰ΩïÂÆû‰Ωì\"\n",
    "            \n",
    "            message = {\n",
    "                \"instruction\": \"\"\"‰Ω†ÊòØ‰∏Ä‰∏™ÊñáÊú¨ÂÆû‰ΩìËØÜÂà´È¢ÜÂüüÁöÑ‰∏ìÂÆ∂Ôºå‰Ω†ÈúÄË¶Å‰ªéÁªôÂÆöÁöÑÂè•Â≠ê‰∏≠ÊèêÂèñ Âú∞ÁÇπ; ‰∫∫Âêç; Âú∞ÁêÜÂÆû‰Ωì; ÁªÑÁªá ÂÆû‰Ωì. ‰ª• json Ê†ºÂºèËæìÂá∫, Â¶Ç {\"entity_text\": \"Âçó‰∫¨\", \"entity_label\": \"Âú∞ÁêÜÂÆû‰Ωì\"} Ê≥®ÊÑè: 1. ËæìÂá∫ÁöÑÊØè‰∏ÄË°åÈÉΩÂøÖÈ°ªÊòØÊ≠£Á°ÆÁöÑ json Â≠óÁ¨¶‰∏≤. 2. Êâæ‰∏çÂà∞‰ªª‰ΩïÂÆû‰ΩìÊó∂, ËæìÂá∫\"Ê≤°ÊúâÊâæÂà∞‰ªª‰ΩïÂÆû‰Ωì\". \"\"\",\n",
    "                \"input\": f\"ÊñáÊú¨:{input_text}\",\n",
    "                \"output\": entity_sentence,\n",
    "            }\n",
    "            \n",
    "            messages.append(message)\n",
    "\n",
    "    # ‰øùÂ≠òÈáçÊûÑÂêéÁöÑJSONLÊñá‰ª∂\n",
    "    with open(new_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        for message in messages:\n",
    "            file.write(json.dumps(message, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "# Âä†ËΩΩ„ÄÅÂ§ÑÁêÜÊï∞ÊçÆÈõÜÂíåÊµãËØïÈõÜ\n",
    "train_dataset_path = \"ccfbdci.jsonl\"\n",
    "train_jsonl_new_path = \"ccf_train.jsonl\"\n",
    "\n",
    "if not os.path.exists(train_jsonl_new_path):\n",
    "    dataset_jsonl_transfer(train_dataset_path, train_jsonl_new_path)\n",
    "\n",
    "total_df = pd.read_json(train_jsonl_new_path, lines=True)\n",
    "train_df = total_df[int(len(total_df) * 0.1):]  # Âèñ90%ÁöÑÊï∞ÊçÆÂÅöËÆ≠ÁªÉÈõÜ\n",
    "test_df = total_df[:int(len(total_df) * 0.1)].sample(n=20)  # ÈöèÊú∫Âèñ10%ÁöÑÊï∞ÊçÆ‰∏≠ÁöÑ20Êù°ÂÅöÊµãËØïÈõÜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4089fe22-d1f3-4e6b-a568-7215afdd95b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ad3e10c-d229-400a-be54-f2f5255dfd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 22:49:58,177 - modelscope - INFO - PyTorch version 2.4.1+cu118 Found.\n",
      "2024-11-04 22:49:58,179 - modelscope - INFO - Loading ast index from C:\\Users\\fhawk\\.cache\\modelscope\\ast_indexer\n",
      "2024-11-04 22:49:58,245 - modelscope - INFO - Loading done! Current index file version is 1.14.0, with md5 d7fef9503ef10c41dd0d7e9f814f7513 and a total number of 976 components indexed\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from modelscope import snapshot_download, AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "# import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bdb0891-79ab-4022-869e-2e7b5a085184",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 659/659 [00:00<00:00, 220kB/s]\n",
      "Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48.0/48.0 [00:00<00:00, 15.8kB/s]\n",
      "Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 242/242 [00:00<00:00, 100kB/s]\n",
      "Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11.1k/11.1k [00:00<00:00, 5.66MB/s]\n",
      "Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.59M/1.59M [00:00<00:00, 13.4MB/s]\n",
      "Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 942M/942M [00:46<00:00, 21.1MB/s]\n",
      "Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.47k/3.47k [00:00<00:00, 2.09MB/s]\n",
      "Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.70M/6.70M [00:00<00:00, 17.6MB/s]\n",
      "Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.26k/1.26k [00:00<00:00, 602kB/s]\n",
      "Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.65M/2.65M [00:00<00:00, 11.1MB/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"qwen/Qwen2-0.5B-Instruct\"    \n",
    "model_dir = \"./qwen/Qwen2-0___5B-Instruct\"\n",
    "\n",
    "# Âú®modelscope‰∏ä‰∏ãËΩΩQwenÊ®°ÂûãÂà∞Êú¨Âú∞ÁõÆÂΩï‰∏ã\n",
    "model_dir = snapshot_download(model_id, cache_dir=\"./\", revision=\"master\")\n",
    "\n",
    "# TransformersÂä†ËΩΩÊ®°ÂûãÊùÉÈáç\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, use_fast=False, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir, device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "model.enable_input_require_grads()  # ÂºÄÂêØÊ¢ØÂ∫¶Ê£ÄÊü•ÁÇπÊó∂ÔºåË¶ÅÊâßË°åËØ•ÊñπÊ≥ï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c1a573-60c7-4255-b21e-fc204ac50ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e96248a4-6f61-43c9-8019-ca8ed30c2cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_func(example):\n",
    "    \"\"\"\n",
    "    Â∞ÜÊï∞ÊçÆÈõÜËøõË°åÈ¢ÑÂ§ÑÁêÜ, Â§ÑÁêÜÊàêÊ®°ÂûãÂèØ‰ª•Êé•ÂèóÁöÑÊ†ºÂºè\n",
    "    \"\"\"\n",
    "\n",
    "    MAX_LENGTH = 384 \n",
    "    input_ids, attention_mask, labels = [], [], []\n",
    "    system_prompt = \"\"\"‰Ω†ÊòØ‰∏Ä‰∏™ÊñáÊú¨ÂÆû‰ΩìËØÜÂà´È¢ÜÂüüÁöÑ‰∏ìÂÆ∂Ôºå‰Ω†ÈúÄË¶Å‰ªéÁªôÂÆöÁöÑÂè•Â≠ê‰∏≠ÊèêÂèñ Âú∞ÁÇπ; ‰∫∫Âêç; Âú∞ÁêÜÂÆû‰Ωì; ÁªÑÁªá ÂÆû‰Ωì. ‰ª• json Ê†ºÂºèËæìÂá∫, Â¶Ç {\"entity_text\": \"Âçó‰∫¨\", \"entity_label\": \"Âú∞ÁêÜÂÆû‰Ωì\"} Ê≥®ÊÑè: 1. ËæìÂá∫ÁöÑÊØè‰∏ÄË°åÈÉΩÂøÖÈ°ªÊòØÊ≠£Á°ÆÁöÑ json Â≠óÁ¨¶‰∏≤. 2. Êâæ‰∏çÂà∞‰ªª‰ΩïÂÆû‰ΩìÊó∂, ËæìÂá∫\"Ê≤°ÊúâÊâæÂà∞‰ªª‰ΩïÂÆû‰Ωì\".\"\"\"\n",
    "    \n",
    "    instruction = tokenizer(\n",
    "        f\"<|im_start|>system\\n{system_prompt}<|im_end|>\\n<|im_start|>user\\n{example['input']}<|im_end|>\\n<|im_start|>assistant\\n\",\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    "    response = tokenizer(f\"{example['output']}\", add_special_tokens=False)\n",
    "    input_ids = instruction[\"input_ids\"] + response[\"input_ids\"] + [tokenizer.pad_token_id]\n",
    "    attention_mask = (\n",
    "        instruction[\"attention_mask\"] + response[\"attention_mask\"] + [1]\n",
    "    )\n",
    "    labels = [-100] * len(instruction[\"input_ids\"]) + response[\"input_ids\"] + [tokenizer.pad_token_id]\n",
    "    if len(input_ids) > MAX_LENGTH:  # ÂÅö‰∏Ä‰∏™Êà™Êñ≠\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01637d67-8c8c-4303-b915-2a080aa4a532",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14152/14152 [00:16<00:00, 871.01 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "train_dataset = train_ds.map(process_func, remove_columns=train_ds.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c426a325-6d97-4421-b15a-e8e1161d22dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],\n",
    "    inference_mode=False,  # ËÆ≠ÁªÉÊ®°Âºè\n",
    "    r=8,  # Lora Áß©\n",
    "    lora_alpha=32,  # Lora alaphÔºåÂÖ∑‰Ωì‰ΩúÁî®ÂèÇËßÅ Lora ÂéüÁêÜ\n",
    "    lora_dropout=0.1,  # Dropout ÊØî‰æã\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72977b7e-1869-4b81-a3c8-c7d19974dd5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98ed05ed-45ce-40fe-960c-8aea3f36a090",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"./output/Qwen2-0.5B-NER\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_steps=10,\n",
    "    num_train_epochs=2,\n",
    "    save_steps=100,\n",
    "    learning_rate=1e-4,\n",
    "    save_on_each_node=True,\n",
    "    gradient_checkpointing=True,\n",
    "    report_to=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724e1a91-3b74-4abe-9dd8-d82c0eb0e3f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4934d58c-45b2-4f76-8e6e-f7dc1c4a9706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from swanlab.integration.huggingface import SwanLabCallback\n",
    "import swanlab\n",
    "\n",
    "swanlab_callback = SwanLabCallback(\n",
    "    project=\"Qwen2-0__5B-NER-fintune\",\n",
    "    experiment_name=\"Qwen2-0.5B-Instruct\",\n",
    "    description=\"‰ΩøÁî®ÈÄö‰πâÂçÉÈóÆQwen2-0.5B-InstructÊ®°ÂûãÂú®NERÊï∞ÊçÆÈõÜ‰∏äÂæÆË∞ÉÔºåÂÆûÁé∞ÂÖ≥ÈîÆÂÆû‰ΩìËØÜÂà´‰ªªÂä°„ÄÇ\",\n",
    "    config={\n",
    "        \"model\": model_id,\n",
    "        \"model_dir\": model_dir,\n",
    "        \"dataset\": \"qgyd2021/chinese_ner_sft\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e0af17-5564-48e0-897b-c62fd83fb95f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "53d52b10-6ffd-4b24-a0f8-4e75676c8c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: swanlab version 0.3.23 is available!  Upgrade: `pip install -U swanlab`\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: Tracking run with swanlab version 0.3.9                                   \n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: Run data will be saved locally in \u001b[35m\u001b[1mD:\\qwen2\\swanlog\\run-20241104_225341-a3b1799d\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: üëã Hi \u001b[1m\u001b[39mWXYS1209\u001b[0m\u001b[0m, welcome to swanlab!\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: Syncing run \u001b[33mQwen2-0.5B-Instruct_Nov04_22-53-41\u001b[0m to the cloud\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: üåü Run `\u001b[1mswanlab watch -l D:\\qwen2\\swanlog\u001b[0m` to view SwanLab Experiment Dashboard locally\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: üè† View project at \u001b[34m\u001b[4mhttps://swanlab.cn/@WXYS1209/Qwen2-0__5B-NER-fintune\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://swanlab.cn/@WXYS1209/Qwen2-0__5B-NER-fintune/runs/gbaadx7mq7cebgvd69jxf\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "    <meta charset=\"UTF-8\">\n",
       "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
       "    <title>Show Iframe</title>\n",
       "    \n",
       "        <script>\n",
       "            function showIframe() {\n",
       "                var iframeHtml = '<iframe src=\"https://swanlab.cn/@WXYS1209/Qwen2-0__5B-NER-fintune/runs/gbaadx7mq7cebgvd69jxf\" width=100% height=\"600\" frameborder=\"no\"></iframe>';\n",
       "                document.getElementById('iframeContainer').innerHTML = iframeHtml;\n",
       "            }\n",
       "        </script>\n",
       "        \n",
       "</head>\n",
       "<body>\n",
       "    <style>\n",
       "        .interactive-button {\n",
       "            display: flex;\n",
       "            align-items: center;\n",
       "            height: 36px;\n",
       "            border: 0px;\n",
       "            background-color: #2c8f63;\n",
       "            color: white;\n",
       "            padding: 10px 20px;\n",
       "            transition: background-color 0.3s, transform 0.2s;\n",
       "        }\n",
       "\n",
       "        .interactive-button:hover {\n",
       "            background-color: #5cab87;\n",
       "            cursor: pointer;\n",
       "        }\n",
       "\n",
       "        .interactive-button:active {\n",
       "            background-color: #217952;\n",
       "            transform: scale(0.96);\n",
       "        }\n",
       "    </style>\n",
       "    <br>\n",
       "    <button onclick=\"showIframe()\" class=\"interactive-button\">\n",
       "        <svg style=\"height: 16px; margin-right: 8px;\" viewBox=\"0 0 46 46\" fill=\"none\">\n",
       "            <path\n",
       "                d=\"M10.8439 21.1974C10.6414 21.2854 10.4477 21.3925 10.2655 21.5173L10.2069 21.5652C10.1839 21.58 10.1625 21.5969 10.1429 21.6159C6.29135 24.6118 4.22831 29.4416 5.32646 34.282C5.94656 37.0577 7.50461 39.5348 9.73801 41.2958C11.9714 43.0568 14.7436 43.994 17.5874 43.9495H18.0219C19.8864 43.8697 21.7087 43.3694 23.3526 42.486C24.9964 41.6026 26.4193 40.3589 27.5147 38.848C28.61 37.3371 29.3496 35.598 29.678 33.761C30.0065 31.9239 29.9153 30.0363 29.4112 28.2395C28.9181 26.4723 27.8919 24.8437 26.9937 23.2551C25.4158 20.4653 23.8343 17.6764 22.2492 14.8884C21.7801 14.0647 21.3057 13.2465 20.8419 12.4228C20.2315 11.3353 19.2746 10.1519 19.224 8.86183C19.1733 7.57176 20.2235 6.32701 21.5082 6.07912C23.9284 5.61801 25.0639 8.24078 25.0693 8.23812C25.363 8.94035 25.9123 9.50489 26.6063 9.81764C27.3002 10.1304 28.087 10.168 28.8077 9.92298C29.5283 9.67791 30.1291 9.1684 30.4885 8.49743C30.8479 7.82646 30.9392 7.04405 30.7439 6.30835C30.1514 4.37314 28.9133 2.69953 27.2363 1.56656C25.7615 0.511704 23.9847 -0.0372109 22.1719 0.00195984C20.9049 0.00893199 19.6532 0.27989 18.4967 0.797557C17.3402 1.31522 16.3043 2.06823 15.4551 3.00856C14.49 4.08707 13.7984 5.38193 13.4389 6.78385C13.0794 8.18576 13.0624 9.6536 13.3894 11.0635C13.52 11.593 13.6984 12.1095 13.9225 12.6067C14.5595 14.0514 15.4951 15.3681 16.284 16.7355C17.2525 18.4147 18.2209 20.0948 19.1893 21.7758C20.1578 23.4568 21.1351 25.1449 22.1213 26.8401C22.9209 28.2421 23.7925 29.4682 23.8805 31.1528C23.9175 32.0513 23.7682 32.9479 23.4419 33.7859C23.1156 34.6239 22.6194 35.3854 21.9845 36.0223C21.3496 36.6592 20.5897 37.1578 19.7527 37.4868C18.9157 37.8157 18.0196 37.9678 17.121 37.9336C14.0024 37.7923 11.6488 35.4814 11.1744 32.4588C10.58 28.6419 13.552 26.5469 13.552 26.5469C14.1782 26.1785 14.6497 25.5955 14.8791 24.906C15.1084 24.2166 15.0801 23.4673 14.7993 22.7971C14.5186 22.127 14.0044 21.5813 13.3521 21.2611C12.6998 20.941 11.9536 20.8682 11.2517 21.0561C11.1174 21.0939 10.9856 21.1402 10.8572 21.1947\"\n",
       "                fill=\"white\"\n",
       "            />\n",
       "            <path\n",
       "                d=\"M42.8101 31.5968C42.8109 30.5198 42.7218 29.4445 42.5435 28.3823C42.2663 26.7069 41.7464 25.0808 41.0002 23.5552C40.5524 22.6463 39.9874 21.7374 39.1024 21.2417C38.6593 20.9919 38.1589 20.8617 37.6502 20.8639C37.1416 20.8661 36.6423 21.0006 36.2013 21.2541C35.7604 21.5077 35.393 21.8716 35.1352 22.3101C34.8775 22.7485 34.7382 23.2466 34.7312 23.7552C34.7072 24.8773 35.3149 25.8875 35.768 26.9217C36.5212 28.6453 36.8623 30.5208 36.7642 32.3993C36.6661 34.2777 36.1315 36.1075 35.2029 37.7433C35.146 37.8404 35.0952 37.941 35.051 38.0445C34.8623 38.4842 34.7635 38.9573 34.7605 39.4358C34.7802 40.1222 35.0356 40.7808 35.4835 41.3011C35.9315 41.8214 36.5449 42.1717 37.2207 42.2932C38.8759 42.589 40.1899 41.347 40.8856 39.9609C42.1643 37.3589 42.823 34.4961 42.8101 31.5968Z\"\n",
       "                fill=\"white\"\n",
       "            />\n",
       "            <path\n",
       "                d=\"M28.2309 11.8938C28.1761 11.9043 28.1218 11.9176 28.0683 11.9338C27.9593 11.9642 27.8611 12.0249 27.7851 12.1088C27.7091 12.1928 27.6584 12.2965 27.6389 12.408C27.6193 12.5195 27.6318 12.6343 27.6748 12.7391C27.7178 12.8438 27.7895 12.9343 27.8818 12.9999C29.2375 14.0252 30.3809 15.3043 31.2482 16.7662C31.4838 17.1677 31.6888 17.5865 31.8612 18.0189C32.0052 18.3921 32.1971 18.8799 32.6822 18.8532C33.0607 18.8346 33.2153 18.512 33.3192 18.1895C33.8137 16.5125 33.9678 14.7534 33.7723 13.0159C33.6331 12.0693 33.4155 11.1359 33.122 10.2252C33.0775 10.0047 32.9744 9.80029 32.8235 9.6335C32.7273 9.54627 32.6054 9.49262 32.4761 9.4806C32.3468 9.46859 32.2171 9.49886 32.1065 9.56687C32.0016 9.65188 31.9115 9.75365 31.8399 9.86806C31.3956 10.4658 30.825 10.9581 30.1687 11.3101C29.8377 11.4861 29.4893 11.6272 29.1292 11.7312C28.828 11.8192 28.5215 11.8325 28.2309 11.8938Z\"\n",
       "                fill=\"white\"\n",
       "            />\n",
       "        </svg>\n",
       "        Display SwanLab Board\n",
       "    </button>\n",
       "    <br>\n",
       "    <div id=\"iframeContainer\"></div>\n",
       "</body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\transformers\\models\\qwen2\\modeling_qwen2.py:679: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1768' max='1768' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1768/1768 28:22, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.791600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.130200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.141200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.093500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.115000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.053600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.120300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.102700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.107500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.088600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.094800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.101900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.084300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.099200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.088500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.069000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.054500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.080800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.078800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.073700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.070400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.077100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.069500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.068300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.050400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.037300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.054300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.072400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.045500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.050100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.077100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.064600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.044700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.059300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.056700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.063200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.045400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.051900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.051800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.050600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.048500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.081000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.057700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.042800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.041800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.053900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.051900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.050100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.048600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.038300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.038000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.069600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.062300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.038800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.037600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.034600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.044800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.059900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.046400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.054900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.037100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.047900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.042100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.056000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.056200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.067400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.036600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.039800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.044900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.053700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.049000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.026700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.054200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.043800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.031200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.046700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.031500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.046800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.045200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.032600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.064400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.047800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.047800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.039300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.035500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.034300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.033300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.034700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.031400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.021600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.016800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.041800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.032100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.023900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.039200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.023000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>0.048100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.034000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>0.035500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.022700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.033400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.024800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>0.028500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>0.020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.033300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>0.044300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.028500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>0.037900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.030900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.027400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.034100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>0.021600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.027200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>0.016500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.025500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>0.021400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0.022100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>0.025700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.041600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.023800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.033200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>0.034800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>0.025300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.025100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1310</td>\n",
       "      <td>0.032100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.041000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1330</td>\n",
       "      <td>0.018200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>0.024500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.027300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1370</td>\n",
       "      <td>0.023100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.028500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1390</td>\n",
       "      <td>0.048100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.019700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1410</td>\n",
       "      <td>0.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>0.019700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1430</td>\n",
       "      <td>0.040200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.022600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.025200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>0.027900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470</td>\n",
       "      <td>0.025300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>0.033900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1490</td>\n",
       "      <td>0.024500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.023700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1510</td>\n",
       "      <td>0.017100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>0.029000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1530</td>\n",
       "      <td>0.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>0.025600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.016300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.030400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1570</td>\n",
       "      <td>0.028900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>0.017800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1590</td>\n",
       "      <td>0.029700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.028300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1610</td>\n",
       "      <td>0.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.022600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1630</td>\n",
       "      <td>0.033200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1640</td>\n",
       "      <td>0.022800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.030700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>0.022100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1670</td>\n",
       "      <td>0.023800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.023700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1690</td>\n",
       "      <td>0.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.031600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1710</td>\n",
       "      <td>0.019600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1720</td>\n",
       "      <td>0.016400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1730</td>\n",
       "      <td>0.034100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.028200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760</td>\n",
       "      <td>0.020900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in ./qwen\\Qwen2-0___5B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in ./qwen\\Qwen2-0___5B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in ./qwen\\Qwen2-0___5B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in ./qwen\\Qwen2-0___5B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in ./qwen\\Qwen2-0___5B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in ./qwen\\Qwen2-0___5B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in ./qwen\\Qwen2-0___5B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in ./qwen\\Qwen2-0___5B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in ./qwen\\Qwen2-0___5B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in ./qwen\\Qwen2-0___5B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in ./qwen\\Qwen2-0___5B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in ./qwen\\Qwen2-0___5B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in ./qwen\\Qwen2-0___5B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in ./qwen\\Qwen2-0___5B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in ./qwen\\Qwen2-0___5B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in ./qwen\\Qwen2-0___5B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in ./qwen\\Qwen2-0___5B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1768, training_loss=0.048037479509393015, metrics={'train_runtime': 1710.1913, 'train_samples_per_second': 16.55, 'train_steps_per_second': 1.034, 'total_flos': 1.064636454615552e+16, 'train_loss': 0.048037479509393015, 'epoch': 1.9988694177501414})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n",
      "\u001b[33mswanlab\u001b[0m: network error, swanlab will resume uploads when the network improves\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    "    callbacks=[swanlab_callback],\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf46b251-9aa6-4b0c-88fd-018b5107b081",
   "metadata": {},
   "source": [
    "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
    "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in ./qwen\\Qwen2-1___5B-Instruct - will assume that the vocabulary was not modified.\n",
    "  warnings.warn(\n",
    "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
    "  return fn(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "529d0151-5482-4427-9740-0ac97253823b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = model.to(\"cuda\")\n",
    "import time\n",
    "\n",
    "# ËÆ∞ÂΩïÂºÄÂßãÊó∂Èó¥\n",
    "start_time = time.time()\n",
    "\n",
    "# ‰øùÂ≠òÈ¢ÑÊµãÁªìÊûúÂíåÁúüÂÆûÊ†áÁ≠æ\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    instruction = row[\"instruction\"]\n",
    "    input_value = row[\"input\"]\n",
    "    label_str = row[\"output\"]  # Ëé∑ÂèñÁúüÂÆûÊ†áÁ≠æÂ≠óÁ¨¶‰∏≤\n",
    "\n",
    "    # ÂàÜÈöîÂπ∂Ëß£ÊûêÁúüÂÆûÊ†áÁ≠æ\n",
    "    try:\n",
    "        # ÈÄöËøá \"}{\" Â∞ÜÂ§ö‰∏™ JSON ÂØπË±°ÊãÜÂàÜ‰∏∫Áã¨Á´ãÁöÑÈÉ®ÂàÜÔºåÂπ∂Ê∑ªÂä†‰∏¢Â§±ÁöÑ '}' Âíå '{'\n",
    "        raw_labels = label_str.replace(\"}{\", \"}|{\").split('|')\n",
    "        true_label_list = [json.loads(label) for label in raw_labels]\n",
    "        true_label_list = [f\"{item['entity_text']} {item['entity_label']}\" for item in true_label_list]\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON for row {index}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Â∞ÜÁúüÂÆûÊ†áÁ≠æÁªÑÂêà‰∏∫Â≠óÁ¨¶‰∏≤ÔºåÁî®‰∫é‰∏éÈ¢ÑÊµãÁªìÊûúËøõË°åÊØîËæÉ\n",
    "    true_labels.append(\", \".join(true_label_list))\n",
    "\n",
    "    # ÁîüÊàêÊ∂àÊÅØÊ†ºÂºè\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"{instruction}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{input_value}\"},\n",
    "    ]\n",
    "\n",
    "    # ‰ΩøÁî®Ê®°ÂûãËøõË°åÈ¢ÑÊµã\n",
    "    response = predict(messages, model, tokenizer)\n",
    "\n",
    "    # ËÆ∞ÂΩïÊ®°ÂûãÁöÑÈ¢ÑÊµã\n",
    "    predicted_labels.append(response.strip())\n",
    "\n",
    "# ËÆ∞ÂΩïÁªìÊùüÊó∂Èó¥\n",
    "end_time = time.time()\n",
    "\n",
    "# ËÆ°ÁÆóÊÄªÁî®Êó∂\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Total execution time: {execution_time:.2f} seconds\")\n",
    "\n",
    "# ËÆ°ÁÆóÂπ∂ÊâìÂç∞ÂáÜÁ°ÆÁéá\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e450ea2a-f7bf-4f4c-a613-d40df9ad43bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"entity_text\": \"Âè∞Êπæ\", \"entity_label\": \"Âú∞ÁêÜÂÆû‰Ωì\"}{\"entity_text\": \"Âè∞Êπæ\", \"entity_label\": \"Âú∞ÁêÜÂÆû‰Ωì\"}{\"entity_text\": \"ËÆ∏ÊúùÊ∏Ö\", \"entity_label\": \"‰∫∫Âêç\"}{\"entity_text\": \"ÁéãË¥Ø‰ªÅ\", \"entity_label\": \"‰∫∫Âêç\"}{\"entity_text\": \"Âä†Â∑û\", \"entity_label\": \"Âú∞ÁêÜÂÆû‰Ωì\"}'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.output[1041]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "246eb80f-d2e2-4e7f-8ddd-dac21baffcae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"entity_text\": \"Âè∞Êπæ\", \"entity_label\": \"Âú∞ÁêÜÂÆû‰Ωì\"}{\"entity_text\": \"ËÆ∏ÊúùÊ∏Ö\", \"entity_label\": \"‰∫∫Âêç\"}{\"entity_text\": \"ÁéãË¥Ø‰ªÅ\", \"entity_label\": \"‰∫∫Âêç\"}{\"entity_text\": \"Âä†Â∑û‰∏≠ÈÉ®\", \"entity_label\": \"Âú∞ÁÇπ\"}',\n",
       " '{\"entity_text\": \"ÂÜÖÊîøÈÉ®Ë≠¶ÊîøÁΩ≤Âàë‰∫ãË≠¶ÂØüÂ±Ä\", \"entity_label\": \"ÁªÑÁªá\"}{\"entity_text\": \"Â§ßÈôÜ\", \"entity_label\": \"Âú∞ÁêÜÂÆû‰Ωì\"}{\"entity_text\": \"‰∏≠ÂõΩ\", \"entity_label\": \"Âú∞ÁêÜÂÆû‰Ωì\"}{\"entity_text\": \"Êµ∑Â≥°‰∏§Â≤∏\", \"entity_label\": \"Âú∞ÁÇπ\"}{\"entity_text\": \"Êù®ÂÖâÂçó\", \"entity_label\": \"‰∫∫Âêç\"}{\"entity_text\": \"Âè∞Êπæ\", \"entity_label\": \"Âú∞ÁêÜÂÆû‰Ωì\"}{\"entity_text\": \"Â§ßÈôÜ\", \"entity_label\": \"Âú∞ÁêÜÂÆû‰Ωì\"}',\n",
       " '{\"entity_text\": \"Áßë‰ªÄÂõæÂ∞ºÂØü\", \"entity_label\": \"‰∫∫Âêç\"}{\"entity_text\": \"ÂèçÂØπËøêÂä®\", \"entity_label\": \"ÁªÑÁªá\"}{\"entity_text\": \"Â°ûÂ∞îÁª¥‰∫öÊ∞ë‰∏ªÂÖö\", \"entity_label\": \"ÁªÑÁªá\"}',\n",
       " '{\"entity_text\": \"Ê≥ïÂ≠¶Èô¢\", \"entity_label\": \"ÁªÑÁªá\"}{\"entity_text\": \"Â∑¶‰∏ΩÂç°\", \"entity_label\": \"‰∫∫Âêç\"}',\n",
       " '{\"entity_text\": \"ÂΩ≠Êò•Ááï\", \"entity_label\": \"‰∫∫Âêç\"}{\"entity_text\": \"ÂΩ≠Êò•Ááï\", \"entity_label\": \"‰∫∫Âêç\"}',\n",
       " '{\"entity_text\": \"Ë∂äÂçó\", \"entity_label\": \"Âú∞ÁêÜÂÆû‰Ωì\"}{\"entity_text\": \"ÂÖãÊûóÈ°ø\", \"entity_label\": \"‰∫∫Âêç\"}',\n",
       " '{\"entity_text\": \"‰∫öÂ§™ÁªèÂêà‰ºö\", \"entity_label\": \"ÁªÑÁªá\"}',\n",
       " '{\"entity_text\": \"Â∑¥Â∞îÊë©Áâπ\", \"entity_label\": \"‰∫∫Âêç\"}{\"entity_text\": \"ÂüÉÊñØÁâπÊãâËææ\", \"entity_label\": \"‰∫∫Âêç\"}',\n",
       " '{\"entity_text\": \"È¶ôÊ∏Ø\", \"entity_label\": \"Âú∞ÁêÜÂÆû‰Ωì\"}{\"entity_text\": \"Ê∑±Âú≥\", \"entity_label\": \"Âú∞ÁêÜÂÆû‰Ωì\"}',\n",
       " '{\"entity_text\": \"ÂçóÈü©Â§ñ‰∫§ÈÉ®\", \"entity_label\": \"ÁªÑÁªá\"}{\"entity_text\": \"ÂçóÈü©ÊîøÂ∫ú\", \"entity_label\": \"ÁªÑÁªá\"}{\"entity_text\": \"‰∏≠ÂÖ±ÊîøÂ∫ú\", \"entity_label\": \"ÁªÑÁªá\"}{\"entity_text\": \"ÂåóÈü©\", \"entity_label\": \"Âú∞ÁêÜÂÆû‰Ωì\"}',\n",
       " '{\"entity_text\": \"È©¨ÊÇ¶ÁÑ∂\", \"entity_label\": \"‰∫∫Âêç\"}{\"entity_text\": \"È´òË°åÂÅ•\", \"entity_label\": \"‰∫∫Âêç\"}{\"entity_text\": \"È´òË°åÂÅ•\", \"entity_label\": \"‰∫∫Âêç\"}',\n",
       " '{\"entity_text\": \"‰ª•Ëâ≤Âàó\", \"entity_label\": \"Âú∞ÁêÜÂÆû‰Ωì\"}{\"entity_text\": \"Ê≤ôÈæô\", \"entity_label\": \"‰∫∫Âêç\"}{\"entity_text\": \"ËÅîÂêàÂÖö\", \"entity_label\": \"ÁªÑÁªá\"}{\"entity_text\": \"Â∑¥ÊãâÂÖã\", \"entity_label\": \"‰∫∫Âêç\"}',\n",
       " '{\"entity_text\": \"Ëä¨ÂÖ∞\", \"entity_label\": \"Âú∞ÁêÜÂÆû‰Ωì\"}',\n",
       " '{\"entity_text\": \"ÂõΩÂÆâÂü∫Èáë\", \"entity_label\": \"ÁªÑÁªá\"}',\n",
       " '{\"entity_text\": \"È´òÂøóÂ∞ö\", \"entity_label\": \"‰∫∫Âêç\"}']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "64a62a83-7f94-4ed4-8bde-dd35bdab0e42",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting ',' delimiter: line 1 column 44 (char 43)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m [json\u001b[38;5;241m.\u001b[39mloads(label) \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m label_str\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m label]\n",
      "Cell \u001b[1;32mIn[66], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m [\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m label_str\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m label]\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\pytorch\\lib\\json\\__init__.py:357\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    355\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    356\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\pytorch\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\pytorch\\lib\\json\\decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m \n\u001b[0;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting ',' delimiter: line 1 column 44 (char 43)"
     ]
    }
   ],
   "source": [
    " [json.loads(label) for label in label_str.split('}') if label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "258e6b0b-a19d-4a11-8d6c-eac8f2b070aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ====== ËÆ≠ÁªÉÁªìÊùüÂêéÁöÑÈ¢ÑÊµã ===== #\n",
    "\n",
    "def predict(messages, model, tokenizer):\n",
    "    device = \"cuda\" # \"cuda\"\n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "    generated_ids = model.generate(model_inputs.input_ids, max_new_tokens=512)\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids) :]\n",
    "        for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    print(response)\n",
    "\n",
    "    return response\n",
    "\n",
    "model = model.to(\"cuda\")\n",
    "import time\n",
    "\n",
    "# ËÆ∞ÂΩïÂºÄÂßãÊó∂Èó¥\n",
    "start_time = time.time()\n",
    "\n",
    "test_text_list = []\n",
    "result_list = []\n",
    "for index, row in test_df.iterrows():\n",
    "    instruction = row[\"instruction\"]\n",
    "    input_value = row[\"input\"]\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"{instruction}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{input_value}\"},\n",
    "    ]\n",
    "\n",
    "    response = predict(messages, model, tokenizer)\n",
    "    messages.append({\"role\": \"assistant\", \"content\": f\"{response}\"})\n",
    "    result_text = f\"{messages[0]}\\n\\n{messages[1]}\\n\\n{messages[2]}\"\n",
    "    result_list.append(result_text)\n",
    "    # test_text_list.append(swanlab.Text(result_text, caption=response))\n",
    "\n",
    "# ËÆ∞ÂΩïÁªìÊùüÊó∂Èó¥\n",
    "end_time = time.time()\n",
    "\n",
    "# ËÆ°ÁÆóÊÄªÁî®Êó∂\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# swanlab.log({\"Prediction\": test_text_list})\n",
    "# swanlab.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "409cceda-8dbb-4d6a-a6d4-de8202672a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‰ª£Á†ÅËøêË°åÊó∂Èó¥: 37.08256244659424 Áßí'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"‰ª£Á†ÅËøêË°åÊó∂Èó¥: {execution_time} Áßí\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d26c4dbc-3413-4ea4-8bd4-8961deb83744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Â≠òÂÇ®ÊúÄÁªàÁöÑÊï∞ÊçÆ\n",
    "data = []\n",
    "\n",
    "# ÈÅçÂéÜ result_list Âπ∂Ëß£ÊûêÊØè‰∏™ result_text\n",
    "for idx, result_text in enumerate(result_list):\n",
    "    # ÊèêÂèñÁî®Êà∑ËæìÂÖ•ÁöÑÊñáÊú¨ÂÜÖÂÆπ\n",
    "    user_match = re.search(r\"\\'role\\': \\'user\\', \\'content\\': \\'ÊñáÊú¨:(.*?)\\'\", result_text)\n",
    "    input_text = user_match.group(1) if user_match else \"\"\n",
    "    \n",
    "    # ÊèêÂèñ assistant ËøîÂõûÁöÑÂÆû‰Ωì‰ø°ÊÅØ\n",
    "    assistant_match = re.search(r\"\\'role\\': \\'assistant\\', \\'content\\': \\'(.*?)\\'\", result_text)\n",
    "    assistant_content = assistant_match.group(1) if assistant_match else \"\"\n",
    "    \n",
    "    # ‰ΩøÁî®Ê≠£ÂàôË°®ËææÂºèÊèêÂèñÊØè‰∏™ entity_text Âíå entity_label\n",
    "    entities = re.findall(r\"\\{\\\"entity_text\\\": \\\"(.*?)\\\", \\\"entity_label\\\": \\\"(.*?)\\\"\\}\", assistant_content)\n",
    "    for entity_text, entity_label in entities:\n",
    "        # Â∞Ü idÔºàÁ¥¢ÂºïÔºâ„ÄÅtext„ÄÅlabel Ê∑ªÂä†Âà∞ data ‰∏≠\n",
    "        data.append({\"id\": idx, \"text\": entity_text, \"label\": entity_label})\n",
    "\n",
    "# Â∞Ü data ËΩ¨Êç¢‰∏∫ DataFrame\n",
    "df_entities = pd.DataFrame(data)\n",
    "\n",
    "# ÊòæÁ§∫ÁªìÊûú\n",
    "print(df_entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ed882a0-f8c0-415d-b004-156361e878bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Âè∞Êπæ</td>\n",
       "      <td>Âú∞ÁêÜÂÆû‰Ωì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ËÆ∏ÊúùÊ∏Ö</td>\n",
       "      <td>‰∫∫Âêç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>ÁéãË¥Ø‰ªÅ</td>\n",
       "      <td>‰∫∫Âêç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Âä†Â∑û‰∏≠ÈÉ®</td>\n",
       "      <td>Âú∞ÁÇπ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ÂÜÖÊîøÈÉ®Ë≠¶ÊîøÁΩ≤Âàë‰∫ãË≠¶ÂØüÂ±Ä</td>\n",
       "      <td>ÁªÑÁªá</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Â§ßÈôÜ</td>\n",
       "      <td>Âú∞ÁêÜÂÆû‰Ωì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>‰∏≠ÂõΩ</td>\n",
       "      <td>Âú∞ÁêÜÂÆû‰Ωì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Êµ∑Â≥°‰∏§Â≤∏</td>\n",
       "      <td>Âú∞ÁÇπ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Êù®ÂÖâÂçó</td>\n",
       "      <td>‰∫∫Âêç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Âè∞Êπæ</td>\n",
       "      <td>Âú∞ÁêÜÂÆû‰Ωì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>Â§ßÈôÜ</td>\n",
       "      <td>Âú∞ÁêÜÂÆû‰Ωì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>Áßë‰ªÄÂõæÂ∞ºÂØü</td>\n",
       "      <td>‰∫∫Âêç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>Ê≥ïÂ≠¶Èô¢</td>\n",
       "      <td>ÁªÑÁªá</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>Â∑¶‰∏ΩÂç°</td>\n",
       "      <td>‰∫∫Âêç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>ÂΩ≠Êò•Ááï</td>\n",
       "      <td>‰∫∫Âêç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>ÂΩ≠Êò•Ááï</td>\n",
       "      <td>‰∫∫Âêç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8</td>\n",
       "      <td>Ë∂äÂçó</td>\n",
       "      <td>Âú∞ÁêÜÂÆû‰Ωì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>ÂÖãÊûóÈ°ø</td>\n",
       "      <td>‰∫∫Âêç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>Ë∂äÂçóÊîøÂ∫ú</td>\n",
       "      <td>ÁªÑÁªá</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9</td>\n",
       "      <td>Ê£ÆÂÜÖÈòÅ</td>\n",
       "      <td>ÁªÑÁªá</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10</td>\n",
       "      <td>‰∫öÂ§™ÁªèÂêà‰ºö</td>\n",
       "      <td>ÁªÑÁªá</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11</td>\n",
       "      <td>Â∑¥Â∞îÊë©Áâπ</td>\n",
       "      <td>‰∫∫Âêç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11</td>\n",
       "      <td>ÂüÉÊñØÁâπÊãâËææ</td>\n",
       "      <td>‰∫∫Âêç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12</td>\n",
       "      <td>È¶ôÊ∏Ø</td>\n",
       "      <td>Âú∞ÁêÜÂÆû‰Ωì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12</td>\n",
       "      <td>Ê∑±Âú≥</td>\n",
       "      <td>Âú∞ÁêÜÂÆû‰Ωì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13</td>\n",
       "      <td>ÂçóÈü©Â§ñ‰∫§ÈÉ®</td>\n",
       "      <td>ÁªÑÁªá</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13</td>\n",
       "      <td>ÂçóÈü©ÊîøÂ∫ú</td>\n",
       "      <td>ÁªÑÁªá</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13</td>\n",
       "      <td>‰∏≠ÂÖ±ÊîøÂ∫ú</td>\n",
       "      <td>ÁªÑÁªá</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13</td>\n",
       "      <td>ÂåóÈü©</td>\n",
       "      <td>Âú∞ÁêÜÂÆû‰Ωì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>14</td>\n",
       "      <td>È©¨ÊÇ¶ÁÑ∂</td>\n",
       "      <td>‰∫∫Âêç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>14</td>\n",
       "      <td>È´òË°åÂÅ•</td>\n",
       "      <td>‰∫∫Âêç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>14</td>\n",
       "      <td>È´òË°åÂÅ•</td>\n",
       "      <td>‰∫∫Âêç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>16</td>\n",
       "      <td>‰ª•Ëâ≤Âàó</td>\n",
       "      <td>Âú∞ÁêÜÂÆû‰Ωì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>16</td>\n",
       "      <td>Ê≤ôÈæô</td>\n",
       "      <td>‰∫∫Âêç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>16</td>\n",
       "      <td>ËÅîÂêàÂÖö</td>\n",
       "      <td>ÁªÑÁªá</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>16</td>\n",
       "      <td>Â∑¥ÊãâÂÖã</td>\n",
       "      <td>‰∫∫Âêç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>17</td>\n",
       "      <td>Ëä¨ÂÖ∞</td>\n",
       "      <td>Âú∞ÁêÜÂÆû‰Ωì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>18</td>\n",
       "      <td>ÂõΩÂÆâÂü∫Èáë</td>\n",
       "      <td>ÁªÑÁªá</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>19</td>\n",
       "      <td>È´òÂøóÂ∞ö</td>\n",
       "      <td>‰∫∫Âêç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>19</td>\n",
       "      <td>ÔΩÅÔΩêÔΩÖÔΩÉÂïÜÂä°ÊóÖË°åÂç°</td>\n",
       "      <td>ÁªÑÁªá</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>19</td>\n",
       "      <td>Êæ≥Ê¥≤</td>\n",
       "      <td>Âú∞ÁêÜÂÆû‰Ωì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>19</td>\n",
       "      <td>Ëè≤ÂæãÂÆæ</td>\n",
       "      <td>Âú∞ÁêÜÂÆû‰Ωì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>19</td>\n",
       "      <td>ÂçóÈü©</td>\n",
       "      <td>Âú∞ÁêÜÂÆû‰Ωì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>19</td>\n",
       "      <td>Á∫ΩË•øÂÖ∞</td>\n",
       "      <td>Âú∞ÁêÜÂÆû‰Ωì</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id         text label\n",
       "0    0           Âè∞Êπæ  Âú∞ÁêÜÂÆû‰Ωì\n",
       "1    0          ËÆ∏ÊúùÊ∏Ö    ‰∫∫Âêç\n",
       "2    0          ÁéãË¥Ø‰ªÅ    ‰∫∫Âêç\n",
       "3    0         Âä†Â∑û‰∏≠ÈÉ®    Âú∞ÁÇπ\n",
       "4    1  ÂÜÖÊîøÈÉ®Ë≠¶ÊîøÁΩ≤Âàë‰∫ãË≠¶ÂØüÂ±Ä    ÁªÑÁªá\n",
       "5    1           Â§ßÈôÜ  Âú∞ÁêÜÂÆû‰Ωì\n",
       "6    1           ‰∏≠ÂõΩ  Âú∞ÁêÜÂÆû‰Ωì\n",
       "7    1         Êµ∑Â≥°‰∏§Â≤∏    Âú∞ÁÇπ\n",
       "8    1          Êù®ÂÖâÂçó    ‰∫∫Âêç\n",
       "9    1           Âè∞Êπæ  Âú∞ÁêÜÂÆû‰Ωì\n",
       "10   1           Â§ßÈôÜ  Âú∞ÁêÜÂÆû‰Ωì\n",
       "11   2        Áßë‰ªÄÂõæÂ∞ºÂØü    ‰∫∫Âêç\n",
       "12   3          Ê≥ïÂ≠¶Èô¢    ÁªÑÁªá\n",
       "13   3          Â∑¶‰∏ΩÂç°    ‰∫∫Âêç\n",
       "14   5          ÂΩ≠Êò•Ááï    ‰∫∫Âêç\n",
       "15   5          ÂΩ≠Êò•Ááï    ‰∫∫Âêç\n",
       "16   8           Ë∂äÂçó  Âú∞ÁêÜÂÆû‰Ωì\n",
       "17   8          ÂÖãÊûóÈ°ø    ‰∫∫Âêç\n",
       "18   8         Ë∂äÂçóÊîøÂ∫ú    ÁªÑÁªá\n",
       "19   9          Ê£ÆÂÜÖÈòÅ    ÁªÑÁªá\n",
       "20  10        ‰∫öÂ§™ÁªèÂêà‰ºö    ÁªÑÁªá\n",
       "21  11         Â∑¥Â∞îÊë©Áâπ    ‰∫∫Âêç\n",
       "22  11        ÂüÉÊñØÁâπÊãâËææ    ‰∫∫Âêç\n",
       "23  12           È¶ôÊ∏Ø  Âú∞ÁêÜÂÆû‰Ωì\n",
       "24  12           Ê∑±Âú≥  Âú∞ÁêÜÂÆû‰Ωì\n",
       "25  13        ÂçóÈü©Â§ñ‰∫§ÈÉ®    ÁªÑÁªá\n",
       "26  13         ÂçóÈü©ÊîøÂ∫ú    ÁªÑÁªá\n",
       "27  13         ‰∏≠ÂÖ±ÊîøÂ∫ú    ÁªÑÁªá\n",
       "28  13           ÂåóÈü©  Âú∞ÁêÜÂÆû‰Ωì\n",
       "29  14          È©¨ÊÇ¶ÁÑ∂    ‰∫∫Âêç\n",
       "30  14          È´òË°åÂÅ•    ‰∫∫Âêç\n",
       "31  14          È´òË°åÂÅ•    ‰∫∫Âêç\n",
       "32  16          ‰ª•Ëâ≤Âàó  Âú∞ÁêÜÂÆû‰Ωì\n",
       "33  16           Ê≤ôÈæô    ‰∫∫Âêç\n",
       "34  16          ËÅîÂêàÂÖö    ÁªÑÁªá\n",
       "35  16          Â∑¥ÊãâÂÖã    ‰∫∫Âêç\n",
       "36  17           Ëä¨ÂÖ∞  Âú∞ÁêÜÂÆû‰Ωì\n",
       "37  18         ÂõΩÂÆâÂü∫Èáë    ÁªÑÁªá\n",
       "38  19          È´òÂøóÂ∞ö    ‰∫∫Âêç\n",
       "39  19    ÔΩÅÔΩêÔΩÖÔΩÉÂïÜÂä°ÊóÖË°åÂç°    ÁªÑÁªá\n",
       "40  19           Êæ≥Ê¥≤  Âú∞ÁêÜÂÆû‰Ωì\n",
       "41  19          Ëè≤ÂæãÂÆæ  Âú∞ÁêÜÂÆû‰Ωì\n",
       "42  19           ÂçóÈü©  Âú∞ÁêÜÂÆû‰Ωì\n",
       "43  19          Á∫ΩË•øÂÖ∞  Âú∞ÁêÜÂÆû‰Ωì"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0932f350-d3ad-4c1f-9733-b35a5df9a433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in ./qwen\\Qwen2-0___5B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ÂÅáËÆæ‰Ω†Â∑≤ÁªèÂÆåÊàê‰∫ÜÊ®°ÂûãÁöÑÂæÆË∞É\n",
    "# Â∞ÜÊ®°Âûã‰øùÂ≠òÂà∞Êú¨Âú∞ÁõÆÂΩï\n",
    "\n",
    "output_dir = \"./fine_tuned_qwen2\"\n",
    "\n",
    "# ‰øùÂ≠òÊ®°ÂûãÂíåÂàÜËØçÂô®\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(f\"ÂæÆË∞ÉÂêéÁöÑÊ®°ÂûãÂ∑≤‰øùÂ≠òÂà∞: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "112bbaff-ed7e-4af8-92ce-517772708be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"qwen/Qwen2-1.5B-Instruct\"    \n",
    "model_dir = \"./fine_tuned_qwen2\"\n",
    "\n",
    "# Âú®modelscope‰∏ä‰∏ãËΩΩQwenÊ®°ÂûãÂà∞Êú¨Âú∞ÁõÆÂΩï‰∏ã\n",
    "# model_dir = snapshot_download(model_id, cache_dir=\"./\", revision=\"master\")\n",
    "\n",
    "# TransformersÂä†ËΩΩÊ®°ÂûãÊùÉÈáç\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, use_fast=False, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir, device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "model.enable_input_require_grads()  # ÂºÄÂêØÊ¢ØÂ∫¶Ê£ÄÊü•ÁÇπÊó∂ÔºåË¶ÅÊâßË°åËØ•ÊñπÊ≥ï\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb2038d0-f183-4231-b6ec-315eecad0e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 1536)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2SdpaAttention(\n",
       "          (q_proj): lora.Linear(\n",
       "            (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=1536, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=1536, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "          )\n",
       "          (k_proj): lora.Linear(\n",
       "            (base_layer): Linear(in_features=1536, out_features=256, bias=True)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=1536, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=256, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "          )\n",
       "          (v_proj): lora.Linear(\n",
       "            (base_layer): Linear(in_features=1536, out_features=256, bias=True)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=1536, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=256, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "          )\n",
       "          (o_proj): lora.Linear(\n",
       "            (base_layer): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=1536, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=1536, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "          )\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): lora.Linear(\n",
       "            (base_layer): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=1536, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=8960, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "          )\n",
       "          (up_proj): lora.Linear(\n",
       "            (base_layer): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=1536, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=8960, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "          )\n",
       "          (down_proj): lora.Linear(\n",
       "            (base_layer): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=8960, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=1536, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "          )\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm()\n",
       "        (post_attention_layernorm): Qwen2RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382381b3-8a01-4180-8d71-6aefaaa04d15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ed0339-507f-469b-9ca3-31a0859d8d43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(PyTorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
